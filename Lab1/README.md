# Лабораторная работа №1 
### Задание
Перемножение матриц.  
Задача: реализовать алгоритм перемножения матриц  
Язык: C++ или Python  
Входные данные: 2 матрицы размером от 100х100 до 2000х2000 каждая  
Выходные данные: проверка корректности перемножения + время вычисления  

Реализация должна содержать 2 функции перемножения матриц: на CPU и на GPU с
применением CUDA.  


### Описание программы
В программе происходит перемножение двух квадратных матриц размерности N×N, данные для заполнения которых сгенерированы случайным образом.

###Функции:
Filling_m, где случайность данных получается за счёт использования текущего системного времени.
matMulCPU производит последовательное вычисление произведения матриц на хосте.
equals_m проверяет что результирующие матрицы вычисленные на GPU и CPU совпадают.
matMulCuda функция ядра для перемножения матриц на девайсе. 
Ниже приведена таблица времени работы параллельной и последовательной функций для различных размерностей матрицы. Время указано в миллисекундах и получено как среднее по 5 запускам.

Размерность матриц, N | Время работы на GPU, мс | Время работы на CPU, мс | Ускорение
:----:|:-------:|:-----------:|------:
128 | 0,15 | 8,52 | 56,80
256 | 0,63| 92,13 | 146,23
512 | 3,83 | 878,00 | 229,24
1024 | 26,06 | 16234,77 | 622,97
2048 | 190.51 | 181225,90 | 951,26

####Визуализация таблицы.
График времени рассчёта произведения матриц

![](Work_timw.jpg)

Было опробовано засечь время выполнения функции ядра с учетом и без учета пересылки результата с девайса обратно на хост. Результирующее время вышло одинаковым, поэтому в итоге время засекалось с учетом пересылки данных.
### Экспериментальное исследование
В таблице представлены результаты исследования времени работы параллельной и последовательной функций для различных размерностей массива. Значение времени было взято как среднее по 10 запускам.  

Размерность матрицы, N | Время работы функции на GPU, мс | Время работы функции на CPU, мс | CPU/GPU
:----:|:-------:|:-----------:|------:
128 | 892,078 | 45,376 | 0,050
256 | 823,672| 400,066 | 0,485
512 | 880,910 | 3733,903 | 4,238
1024 | 954,268 | 88143,503 | 92,367
2000 | 997,922 | 182086,156 | 182,465

Исследование показало, что время работы части программы, исполняющейся на GPU, очень мало растет с увеличением N и имеет большее время выполнения для маленькой размерности, чем последовательный вариант. Для N=512 параллельная программа становится в 4 раза быстрее. Таким образом, зависимость ускорения от размерности матрицы выше линейной и программа на CUDA дает существенный выигрыш во времени для размерностей матриц >512. Однако, для меньших матриц последовательный алгоритм выигрывает по скорости.  
